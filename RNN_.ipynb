{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":8064,"status":"ok","timestamp":1684301259146,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"ezk85D_wgIWt"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import accuracy_score\n","from keras.datasets import reuters\n","#from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import pad_sequences\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, SimpleRNN, Activation\n","from keras import optimizers\n","from keras.wrappers.scikit_learn import KerasClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vi7Xf519gy35"},"outputs":[],"source":["num_words = 30000\n","maxlen = 50\n","test_split = 0.3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1613,"status":"ok","timestamp":1684285126286,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"9hV3lyIVSP0T","outputId":"72b44ceb-1326-4595-bf47-c76f424670f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n","2110848/2110848 [==============================] - 0s 0us/step\n"]}],"source":["(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words =\n","                num_words, maxlen = maxlen, test_split = test_split)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1684285130404,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"-SnntopIAATv","outputId":"c0692e6b-64c3-48e9-e666-0c9f037212a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 486, 341, 785, 26, 14, 482, 26, 255, 606, 252, 83, 146, 91, 102, 17, 12]\n"]}],"source":["print(X_train[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1684285144978,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"IAeIzq4zN4tn","outputId":"4d4eddf2-f5ed-4f44-a7de-f6ef05131c9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 53, 321, 26, 14, 614, 26, 39, 19, 3611, 18, 14, 32, 5902, 18, 86, 401, 44, 11, 14, 996, 59, 11, 17, 12]\n"]}],"source":["print(X_train[11])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_zcjSXt-hKh-"},"outputs":[],"source":["(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words =\n","                num_words, maxlen = maxlen, test_split = test_split)\n","X_train = pad_sequences(X_train, padding = 'post')\n","X_test = pad_sequences(X_test, padding = 'post')\n","X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n","X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n","y_data = np.concatenate((y_train, y_test))\n","y_data = to_categorical(y_data)\n","y_train = y_data[:1395]\n","y_test = y_data[1395:]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":665,"status":"ok","timestamp":1684285304565,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"1DwGeIMmOZMv","outputId":"77d2d427-35e9-47b8-f58c-f5abb931e18c"},"outputs":[{"data":{"text/plain":["1395"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["len(y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":776,"status":"ok","timestamp":1684285332918,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"1fQN7BvnOmcF","outputId":"e6f0fd21-6301-482e-d267-9ff2022283aa"},"outputs":[{"data":{"text/plain":["599"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["len(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":684,"status":"ok","timestamp":1684248914152,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"jVgjJMbTDtAo","outputId":"911ad570-b882-4d97-b5b9-11808141c9b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n","550378/550378 [==============================] - 0s 0us/step\n"]},{"data":{"text/plain":["236"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["word_index=reuters.get_word_index()\n","word_index['money']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":617,"status":"ok","timestamp":1684249642445,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"sMAryey9GcFS","outputId":"8b58e66e-87b6-490e-dcc8-c0264e4e3fd3"},"outputs":[{"data":{"text/plain":["3"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["word_index['to']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684249689489,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"yvHR6fHIGmY1","outputId":"f253f1b6-d669-4c31-9677-780990c905ad"},"outputs":[{"data":{"text/plain":["10"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["word_index['for']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1684249944336,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"L9p2VATbHJZL","outputId":"15f3a22f-a75e-49ae-d5e7-a8abcba738b9"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'federal'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["index_to_word={}\n","for key,value in word_index.items():\n","  index_to_word[value]=key\n","\n","index_to_word[245]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":411,"status":"ok","timestamp":1684285801089,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"RZjANR4bJjJo","outputId":"8f1baeeb-dc42-4650-d581-ceafeced07df"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}],"source":["print(y_train[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1684250373637,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"BFv6YDtxlPIC","outputId":"3cae6b54-cc4e-41a7-bf53-0da2667a805b"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}],"source":["print(y_train[213])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p4kJtq0pWGBZ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oPfduE2bhNji"},"outputs":[],"source":["def vanilla_rnn():\n","    model = Sequential()\n","    model.add(SimpleRNN(50, input_shape = (49,1), \n","                        return_sequences = False))\n","    model.add(Dense(46))\n","    model.add(Activation('softmax'))\n","    adam = optimizers.Adam(lr = 0.001)\n","    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"pjvVpd7WhXDh","outputId":"677c1148-eb38-4072-c2ca-bd79500f03b1"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-12-7f40999ebbc5>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n","  model = KerasClassifier(build_fn = vanilla_rnn,\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 2s 13ms/step - loss: 2.9514 - accuracy: 0.4674\n","Epoch 2/200\n","28/28 [==============================] - 1s 20ms/step - loss: 1.4240 - accuracy: 0.6860\n","Epoch 3/200\n","28/28 [==============================] - 1s 20ms/step - loss: 1.2294 - accuracy: 0.6875\n","Epoch 4/200\n","28/28 [==============================] - 1s 19ms/step - loss: 1.1875 - accuracy: 0.7147\n","Epoch 5/200\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1694 - accuracy: 0.7147\n","Epoch 6/200\n","28/28 [==============================] - 1s 20ms/step - loss: 1.1628 - accuracy: 0.7147\n","Epoch 7/200\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1593 - accuracy: 0.7147\n","Epoch 8/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1561 - accuracy: 0.7147\n","Epoch 9/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1527 - accuracy: 0.7147\n","Epoch 10/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1531 - accuracy: 0.7147\n","Epoch 11/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1508 - accuracy: 0.7147\n","Epoch 12/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1502 - accuracy: 0.7147\n","Epoch 13/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1484 - accuracy: 0.7147\n","Epoch 14/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1459 - accuracy: 0.7147\n","Epoch 15/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1455 - accuracy: 0.7147\n","Epoch 16/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1451 - accuracy: 0.7147\n","Epoch 17/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1406 - accuracy: 0.7147\n","Epoch 18/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1464 - accuracy: 0.7147\n","Epoch 19/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1451 - accuracy: 0.7147\n","Epoch 20/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1397 - accuracy: 0.7147\n","Epoch 21/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1384 - accuracy: 0.7147\n","Epoch 22/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1392 - accuracy: 0.7147\n","Epoch 23/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1353 - accuracy: 0.7147\n","Epoch 24/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1337 - accuracy: 0.7140\n","Epoch 25/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1341 - accuracy: 0.7147\n","Epoch 26/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1312 - accuracy: 0.7154\n","Epoch 27/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1314 - accuracy: 0.7197\n","Epoch 28/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1283 - accuracy: 0.7161\n","Epoch 29/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1300 - accuracy: 0.7204\n","Epoch 30/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1310 - accuracy: 0.7197\n","Epoch 31/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1280 - accuracy: 0.7247\n","Epoch 32/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1239 - accuracy: 0.7190\n","Epoch 33/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1211 - accuracy: 0.7233\n","Epoch 34/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1169 - accuracy: 0.7219\n","Epoch 35/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1094 - accuracy: 0.7226\n","Epoch 36/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1014 - accuracy: 0.7219\n","Epoch 37/200\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0872 - accuracy: 0.7197\n","Epoch 38/200\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0712 - accuracy: 0.7226\n","Epoch 39/200\n","28/28 [==============================] - 1s 18ms/step - loss: 1.0474 - accuracy: 0.7247\n","Epoch 40/200\n","28/28 [==============================] - 1s 20ms/step - loss: 1.0337 - accuracy: 0.7226\n","Epoch 41/200\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1918 - accuracy: 0.7125\n","Epoch 42/200\n","28/28 [==============================] - 1s 18ms/step - loss: 1.1541 - accuracy: 0.7147\n","Epoch 43/200\n","28/28 [==============================] - 0s 16ms/step - loss: 1.1501 - accuracy: 0.7147\n","Epoch 44/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1489 - accuracy: 0.7147\n","Epoch 45/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1460 - accuracy: 0.7147\n","Epoch 46/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1439 - accuracy: 0.7147\n","Epoch 47/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1432 - accuracy: 0.7147\n","Epoch 48/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1411 - accuracy: 0.7147\n","Epoch 49/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1404 - accuracy: 0.7147\n","Epoch 50/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1394 - accuracy: 0.7147\n","Epoch 51/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1387 - accuracy: 0.7147\n","Epoch 52/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1369 - accuracy: 0.7147\n","Epoch 53/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1345 - accuracy: 0.7147\n","Epoch 54/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1331 - accuracy: 0.7154\n","Epoch 55/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1349 - accuracy: 0.7154\n","Epoch 56/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1261 - accuracy: 0.7168\n","Epoch 57/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1260 - accuracy: 0.7197\n","Epoch 58/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1234 - accuracy: 0.7168\n","Epoch 59/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1176 - accuracy: 0.7176\n","Epoch 60/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.1154 - accuracy: 0.7197\n","Epoch 61/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1083 - accuracy: 0.7197\n","Epoch 62/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.1041 - accuracy: 0.7197\n","Epoch 63/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0857 - accuracy: 0.7197\n","Epoch 64/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0670 - accuracy: 0.7197\n","Epoch 65/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0857 - accuracy: 0.7226\n","Epoch 66/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0378 - accuracy: 0.7226\n","Epoch 67/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0601 - accuracy: 0.7211\n","Epoch 68/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0242 - accuracy: 0.7226\n","Epoch 69/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0767 - accuracy: 0.6667\n","Epoch 70/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0366 - accuracy: 0.7168\n","Epoch 71/200\n","28/28 [==============================] - 0s 12ms/step - loss: 1.0051 - accuracy: 0.7233\n","Epoch 72/200\n","28/28 [==============================] - 0s 11ms/step - loss: 1.0089 - accuracy: 0.7226\n","Epoch 73/200\n","28/28 [==============================] - 0s 13ms/step - loss: 1.0294 - accuracy: 0.7276\n","Epoch 74/200\n","28/28 [==============================] - 1s 19ms/step - loss: 1.0028 - accuracy: 0.7233\n","Epoch 75/200\n","28/28 [==============================] - 1s 18ms/step - loss: 0.9992 - accuracy: 0.7240\n","Epoch 76/200\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9900 - accuracy: 0.7297\n","Epoch 77/200\n","28/28 [==============================] - 1s 20ms/step - loss: 0.9864 - accuracy: 0.7262\n","Epoch 78/200\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9792 - accuracy: 0.7297\n","Epoch 79/200\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9899 - accuracy: 0.7219\n","Epoch 80/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9860 - accuracy: 0.7312\n","Epoch 81/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9806 - accuracy: 0.7226\n","Epoch 82/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9852 - accuracy: 0.7254\n","Epoch 83/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9800 - accuracy: 0.7319\n","Epoch 84/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9747 - accuracy: 0.7204\n","Epoch 85/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9664 - accuracy: 0.7262\n","Epoch 86/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9696 - accuracy: 0.7283\n","Epoch 87/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9700 - accuracy: 0.7355\n","Epoch 88/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9645 - accuracy: 0.7240\n","Epoch 89/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9567 - accuracy: 0.7326\n","Epoch 90/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9590 - accuracy: 0.7355\n","Epoch 91/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9746 - accuracy: 0.7233\n","Epoch 92/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9691 - accuracy: 0.7254\n","Epoch 93/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9595 - accuracy: 0.7369\n","Epoch 94/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9646 - accuracy: 0.7247\n","Epoch 95/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9508 - accuracy: 0.7269\n","Epoch 96/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9464 - accuracy: 0.7319\n","Epoch 97/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9435 - accuracy: 0.7341\n","Epoch 98/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9427 - accuracy: 0.7341\n","Epoch 99/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9386 - accuracy: 0.7319\n","Epoch 100/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9374 - accuracy: 0.7305\n","Epoch 101/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9300 - accuracy: 0.7384\n","Epoch 102/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9402 - accuracy: 0.7276\n","Epoch 103/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9352 - accuracy: 0.7312\n","Epoch 104/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9253 - accuracy: 0.7355\n","Epoch 105/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9170 - accuracy: 0.7348\n","Epoch 106/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9174 - accuracy: 0.7376\n","Epoch 107/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9325 - accuracy: 0.7391\n","Epoch 108/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.9233 - accuracy: 0.7269\n","Epoch 109/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.9151 - accuracy: 0.7333\n","Epoch 110/200\n","28/28 [==============================] - 1s 18ms/step - loss: 0.8980 - accuracy: 0.7369\n","Epoch 111/200\n","28/28 [==============================] - 1s 19ms/step - loss: 0.9000 - accuracy: 0.7369\n","Epoch 112/200\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8860 - accuracy: 0.7376\n","Epoch 113/200\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8924 - accuracy: 0.7398\n","Epoch 114/200\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8781 - accuracy: 0.7391\n","Epoch 115/200\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8802 - accuracy: 0.7412\n","Epoch 116/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8771 - accuracy: 0.7412\n","Epoch 117/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8687 - accuracy: 0.7398\n","Epoch 118/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8701 - accuracy: 0.7362\n","Epoch 119/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8858 - accuracy: 0.7376\n","Epoch 120/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8723 - accuracy: 0.7384\n","Epoch 121/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8739 - accuracy: 0.7369\n","Epoch 122/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8602 - accuracy: 0.7391\n","Epoch 123/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8652 - accuracy: 0.7434\n","Epoch 124/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8542 - accuracy: 0.7427\n","Epoch 125/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8593 - accuracy: 0.7391\n","Epoch 126/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8575 - accuracy: 0.7412\n","Epoch 127/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8928 - accuracy: 0.7348\n","Epoch 128/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8834 - accuracy: 0.7355\n","Epoch 129/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8600 - accuracy: 0.7412\n","Epoch 130/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8619 - accuracy: 0.7384\n","Epoch 131/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8633 - accuracy: 0.7405\n","Epoch 132/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.8531 - accuracy: 0.7312\n","Epoch 133/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8423 - accuracy: 0.7376\n","Epoch 134/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8456 - accuracy: 0.7348\n","Epoch 135/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8512 - accuracy: 0.7398\n","Epoch 136/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8370 - accuracy: 0.7470\n","Epoch 137/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8364 - accuracy: 0.7441\n","Epoch 138/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8342 - accuracy: 0.7376\n","Epoch 139/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8358 - accuracy: 0.7384\n","Epoch 140/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8312 - accuracy: 0.7391\n","Epoch 141/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8309 - accuracy: 0.7419\n","Epoch 142/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8276 - accuracy: 0.7412\n","Epoch 143/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8208 - accuracy: 0.7384\n","Epoch 144/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8194 - accuracy: 0.7405\n","Epoch 145/200\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8186 - accuracy: 0.7477\n","Epoch 146/200\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8239 - accuracy: 0.7427\n","Epoch 147/200\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8415 - accuracy: 0.7398\n","Epoch 148/200\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8497 - accuracy: 0.7376\n","Epoch 149/200\n","28/28 [==============================] - 1s 19ms/step - loss: 0.8325 - accuracy: 0.7441\n","Epoch 150/200\n","28/28 [==============================] - 1s 20ms/step - loss: 0.8220 - accuracy: 0.7398\n","Epoch 151/200\n","28/28 [==============================] - 0s 15ms/step - loss: 0.8127 - accuracy: 0.7405\n","Epoch 152/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8148 - accuracy: 0.7441\n","Epoch 153/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8154 - accuracy: 0.7477\n","Epoch 154/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8577 - accuracy: 0.7362\n","Epoch 155/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8623 - accuracy: 0.7319\n","Epoch 156/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8440 - accuracy: 0.7384\n","Epoch 157/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8409 - accuracy: 0.7398\n","Epoch 158/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8121 - accuracy: 0.7462\n","Epoch 159/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8063 - accuracy: 0.7491\n","Epoch 160/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8084 - accuracy: 0.7455\n","Epoch 161/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7990 - accuracy: 0.7448\n","Epoch 162/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.8063 - accuracy: 0.7405\n","Epoch 163/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7968 - accuracy: 0.7470\n","Epoch 164/200\n","28/28 [==============================] - 0s 17ms/step - loss: 0.8013 - accuracy: 0.7505\n","Epoch 165/200\n","28/28 [==============================] - 1s 17ms/step - loss: 0.7992 - accuracy: 0.7362\n","Epoch 166/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7961 - accuracy: 0.7448\n","Epoch 167/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7909 - accuracy: 0.7470\n","Epoch 168/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7960 - accuracy: 0.7448\n","Epoch 169/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7943 - accuracy: 0.7484\n","Epoch 170/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7955 - accuracy: 0.7448\n","Epoch 171/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7888 - accuracy: 0.7462\n","Epoch 172/200\n","28/28 [==============================] - 0s 13ms/step - loss: 0.7909 - accuracy: 0.7419\n","Epoch 173/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8053 - accuracy: 0.7434\n","Epoch 174/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7831 - accuracy: 0.7541\n","Epoch 175/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.7918 - accuracy: 0.7477\n","Epoch 176/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.8013 - accuracy: 0.7462\n","Epoch 177/200\n","28/28 [==============================] - 0s 16ms/step - loss: 0.7873 - accuracy: 0.7455\n","Epoch 178/200\n","28/28 [==============================] - 1s 21ms/step - loss: 0.7885 - accuracy: 0.7384\n","Epoch 179/200\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7860 - accuracy: 0.7484\n","Epoch 180/200\n","28/28 [==============================] - 1s 19ms/step - loss: 0.7797 - accuracy: 0.7448\n","Epoch 181/200\n","28/28 [==============================] - 1s 20ms/step - loss: 0.7837 - accuracy: 0.7520\n","Epoch 182/200\n","28/28 [==============================] - 1s 21ms/step - loss: 0.8008 - accuracy: 0.7419\n","Epoch 183/200\n","28/28 [==============================] - 0s 14ms/step - loss: 0.8025 - accuracy: 0.7419\n","Epoch 184/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7918 - accuracy: 0.7434\n","Epoch 185/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7944 - accuracy: 0.7398\n","Epoch 186/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7956 - accuracy: 0.7398\n","Epoch 187/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7873 - accuracy: 0.7398\n","Epoch 188/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7820 - accuracy: 0.7441\n","Epoch 189/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7819 - accuracy: 0.7498\n","Epoch 190/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7809 - accuracy: 0.7470\n","Epoch 191/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7752 - accuracy: 0.7434\n","Epoch 192/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7837 - accuracy: 0.7462\n","Epoch 193/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7969 - accuracy: 0.7419\n","Epoch 194/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7738 - accuracy: 0.7477\n","Epoch 195/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7710 - accuracy: 0.7513\n","Epoch 196/200\n","28/28 [==============================] - 0s 11ms/step - loss: 0.7642 - accuracy: 0.7534\n","Epoch 197/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7679 - accuracy: 0.7470\n","Epoch 198/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7608 - accuracy: 0.7455\n","Epoch 199/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7660 - accuracy: 0.7484\n","Epoch 200/200\n","28/28 [==============================] - 0s 12ms/step - loss: 0.7590 - accuracy: 0.7470\n","19/19 [==============================] - 0s 5ms/step\n","0.7612687813021702\n"]}],"source":["model = KerasClassifier(build_fn = vanilla_rnn, \n","                        epochs = 200, batch_size = 50, verbose = 1)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","y_test_ = np.argmax(y_test, axis = 1)\n","print(accuracy_score(y_pred, y_test_))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":387,"status":"ok","timestamp":1684235817672,"user":{"displayName":"Sowmya HK","userId":"12288333963982404914"},"user_tz":-330},"id":"d5SbzXVRiRjo","outputId":"dad40ce9-c4e5-4117-bd85-6d7757ee4139"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n","550378/550378 [==============================] - 0s 0us/step\n"]},{"data":{"text/plain":["236"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["word_index=reuters.get_word_index()\n","\n","word_index['money']"]},{"cell_type":"markdown","metadata":{"id":"BcOUS_AUixkj"},"source":["LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIFrl0RTiyoY"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import accuracy_score\n","from keras.datasets import reuters\n","from keras.utils import pad_sequences\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Activation\n","from keras import optimizers\n","from keras.wrappers.scikit_learn import KerasClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2vzpnFuizQn"},"outputs":[],"source":["num_words = 30000\n","maxlen = 50\n","test_split = 0.3\n","(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words = num_words, maxlen = maxlen, test_split = test_split)\n","X_train = pad_sequences(X_train, padding = 'post')\n","X_test = pad_sequences(X_test, padding = 'post')\n","X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n","X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n","y_data = np.concatenate((y_train, y_test))\n","y_data = to_categorical(y_data)\n","y_train = y_data[:1395]\n","y_test = y_data[1395:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l6KBqbNdi_i7"},"outputs":[],"source":["def lstm():\n","    model = Sequential()\n","    model.add(LSTM(50, input_shape = (49,1), return_sequences = False))\n","    model.add(Dense(46))\n","    model.add(Activation('softmax'))\n","    adam = optimizers.Adam(lr = 0.001)\n","    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o6UFw76FjEEC","outputId":"0b569b5f-65c4-48d4-dc5a-89b790371f81"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-12-c5e9b3f4c93b>:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n","  model = KerasClassifier(build_fn = lstm, epochs = 200, batch_size = 50, verbose = 1)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["28/28 [==============================] - 3s 25ms/step - loss: 2.9909 - accuracy: 0.6265\n","Epoch 2/200\n","28/28 [==============================] - 1s 28ms/step - loss: 1.4352 - accuracy: 0.7147\n","Epoch 3/200\n","28/28 [==============================] - 1s 32ms/step - loss: 1.2089 - accuracy: 0.7147\n","Epoch 4/200\n","28/28 [==============================] - 1s 41ms/step - loss: 1.1673 - accuracy: 0.7147\n","Epoch 5/200\n","28/28 [==============================] - 1s 43ms/step - loss: 1.1455 - accuracy: 0.7147\n","Epoch 6/200\n","28/28 [==============================] - 1s 28ms/step - loss: 1.1334 - accuracy: 0.7147\n","Epoch 7/200\n","28/28 [==============================] - 1s 25ms/step - loss: 1.1155 - accuracy: 0.7147\n","Epoch 8/200\n","28/28 [==============================] - 1s 26ms/step - loss: 1.0644 - accuracy: 0.7147\n","Epoch 9/200\n","28/28 [==============================] - 1s 28ms/step - loss: 1.0096 - accuracy: 0.7283\n","Epoch 10/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9444 - accuracy: 0.7857\n","Epoch 11/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.9000 - accuracy: 0.8014\n","Epoch 12/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8668 - accuracy: 0.7964\n","Epoch 13/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8348 - accuracy: 0.8079\n","Epoch 14/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.8412 - accuracy: 0.8022\n","Epoch 15/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.8391 - accuracy: 0.8129\n","Epoch 16/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7885 - accuracy: 0.8244\n","Epoch 17/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.7834 - accuracy: 0.8151\n","Epoch 18/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7758 - accuracy: 0.8194\n","Epoch 19/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7913 - accuracy: 0.8129\n","Epoch 20/200\n","28/28 [==============================] - 1s 40ms/step - loss: 0.7572 - accuracy: 0.8265\n","Epoch 21/200\n","28/28 [==============================] - 1s 40ms/step - loss: 0.7505 - accuracy: 0.8251\n","Epoch 22/200\n","28/28 [==============================] - 1s 37ms/step - loss: 0.7558 - accuracy: 0.8265\n","Epoch 23/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7521 - accuracy: 0.8229\n","Epoch 24/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7370 - accuracy: 0.8323\n","Epoch 25/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7272 - accuracy: 0.8287\n","Epoch 26/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7212 - accuracy: 0.8308\n","Epoch 27/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7232 - accuracy: 0.8315\n","Epoch 28/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.7150 - accuracy: 0.8301\n","Epoch 29/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7215 - accuracy: 0.8315\n","Epoch 30/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7130 - accuracy: 0.8272\n","Epoch 31/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.7075 - accuracy: 0.8337\n","Epoch 32/200\n","28/28 [==============================] - 1s 50ms/step - loss: 0.6982 - accuracy: 0.8351\n","Epoch 33/200\n","28/28 [==============================] - 2s 59ms/step - loss: 0.7055 - accuracy: 0.8330\n","Epoch 34/200\n","28/28 [==============================] - 2s 76ms/step - loss: 0.6883 - accuracy: 0.8344\n","Epoch 35/200\n","28/28 [==============================] - 2s 74ms/step - loss: 0.6826 - accuracy: 0.8366\n","Epoch 36/200\n","28/28 [==============================] - 1s 53ms/step - loss: 0.6887 - accuracy: 0.8337\n","Epoch 37/200\n","28/28 [==============================] - 1s 52ms/step - loss: 0.6779 - accuracy: 0.8380\n","Epoch 38/200\n","28/28 [==============================] - 1s 52ms/step - loss: 0.6725 - accuracy: 0.8358\n","Epoch 39/200\n","28/28 [==============================] - 2s 55ms/step - loss: 0.6719 - accuracy: 0.8387\n","Epoch 40/200\n","28/28 [==============================] - 2s 70ms/step - loss: 0.6878 - accuracy: 0.8323\n","Epoch 41/200\n","28/28 [==============================] - 2s 62ms/step - loss: 0.6703 - accuracy: 0.8366\n","Epoch 42/200\n","28/28 [==============================] - 2s 63ms/step - loss: 0.6679 - accuracy: 0.8337\n","Epoch 43/200\n","28/28 [==============================] - 1s 43ms/step - loss: 0.6661 - accuracy: 0.8358\n","Epoch 44/200\n","28/28 [==============================] - 1s 30ms/step - loss: 0.6582 - accuracy: 0.8323\n","Epoch 45/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6566 - accuracy: 0.8330\n","Epoch 46/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6448 - accuracy: 0.8373\n","Epoch 47/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6669 - accuracy: 0.8380\n","Epoch 48/200\n","28/28 [==============================] - 1s 28ms/step - loss: 0.7021 - accuracy: 0.8323\n","Epoch 49/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6639 - accuracy: 0.8344\n","Epoch 50/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6492 - accuracy: 0.8423\n","Epoch 51/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6388 - accuracy: 0.8416\n","Epoch 52/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6396 - accuracy: 0.8394\n","Epoch 53/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6321 - accuracy: 0.8430\n","Epoch 54/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6373 - accuracy: 0.8387\n","Epoch 55/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6286 - accuracy: 0.8437\n","Epoch 56/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6267 - accuracy: 0.8401\n","Epoch 57/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6507 - accuracy: 0.8416\n","Epoch 58/200\n","28/28 [==============================] - 1s 42ms/step - loss: 0.6463 - accuracy: 0.8351\n","Epoch 59/200\n","28/28 [==============================] - 1s 41ms/step - loss: 0.6256 - accuracy: 0.8437\n","Epoch 60/200\n","28/28 [==============================] - 1s 37ms/step - loss: 0.6132 - accuracy: 0.8466\n","Epoch 61/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6135 - accuracy: 0.8444\n","Epoch 62/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6110 - accuracy: 0.8452\n","Epoch 63/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.6097 - accuracy: 0.8466\n","Epoch 64/200\n","28/28 [==============================] - 1s 24ms/step - loss: 0.6108 - accuracy: 0.8452\n","Epoch 65/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6127 - accuracy: 0.8437\n","Epoch 66/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6128 - accuracy: 0.8437\n","Epoch 67/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6152 - accuracy: 0.8437\n","Epoch 68/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6001 - accuracy: 0.8459\n","Epoch 69/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5996 - accuracy: 0.8473\n","Epoch 70/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6012 - accuracy: 0.8502\n","Epoch 71/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6005 - accuracy: 0.8452\n","Epoch 72/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.6277 - accuracy: 0.8480\n","Epoch 73/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5849 - accuracy: 0.8495\n","Epoch 74/200\n","28/28 [==============================] - 2s 57ms/step - loss: 0.5801 - accuracy: 0.8509\n","Epoch 75/200\n","28/28 [==============================] - 1s 44ms/step - loss: 0.5800 - accuracy: 0.8466\n","Epoch 76/200\n","28/28 [==============================] - 1s 31ms/step - loss: 0.5826 - accuracy: 0.8559\n","Epoch 77/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5828 - accuracy: 0.8473\n","Epoch 78/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5876 - accuracy: 0.8480\n","Epoch 79/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5804 - accuracy: 0.8530\n","Epoch 80/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5804 - accuracy: 0.8509\n","Epoch 81/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5727 - accuracy: 0.8473\n","Epoch 82/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5732 - accuracy: 0.8480\n","Epoch 83/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.6014 - accuracy: 0.8502\n","Epoch 84/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5871 - accuracy: 0.8466\n","Epoch 85/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5689 - accuracy: 0.8581\n","Epoch 86/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5703 - accuracy: 0.8480\n","Epoch 87/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5747 - accuracy: 0.8459\n","Epoch 88/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5681 - accuracy: 0.8530\n","Epoch 89/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5544 - accuracy: 0.8559\n","Epoch 90/200\n","28/28 [==============================] - 1s 44ms/step - loss: 0.5619 - accuracy: 0.8523\n","Epoch 91/200\n","28/28 [==============================] - 1s 42ms/step - loss: 0.5514 - accuracy: 0.8538\n","Epoch 92/200\n","28/28 [==============================] - 1s 32ms/step - loss: 0.5473 - accuracy: 0.8566\n","Epoch 93/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5377 - accuracy: 0.8595\n","Epoch 94/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5389 - accuracy: 0.8566\n","Epoch 95/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5285 - accuracy: 0.8616\n","Epoch 96/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5283 - accuracy: 0.8631\n","Epoch 97/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5301 - accuracy: 0.8595\n","Epoch 98/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5672 - accuracy: 0.8480\n","Epoch 99/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.5668 - accuracy: 0.8509\n","Epoch 100/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5335 - accuracy: 0.8552\n","Epoch 101/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5335 - accuracy: 0.8616\n","Epoch 102/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5269 - accuracy: 0.8523\n","Epoch 103/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5325 - accuracy: 0.8616\n","Epoch 104/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5424 - accuracy: 0.8523\n","Epoch 105/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5136 - accuracy: 0.8616\n","Epoch 106/200\n","28/28 [==============================] - 1s 42ms/step - loss: 0.4995 - accuracy: 0.8645\n","Epoch 107/200\n","28/28 [==============================] - 1s 41ms/step - loss: 0.5012 - accuracy: 0.8652\n","Epoch 108/200\n","28/28 [==============================] - 1s 34ms/step - loss: 0.5104 - accuracy: 0.8659\n","Epoch 109/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5007 - accuracy: 0.8645\n","Epoch 110/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5210 - accuracy: 0.8573\n","Epoch 111/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.5006 - accuracy: 0.8674\n","Epoch 112/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4952 - accuracy: 0.8667\n","Epoch 113/200\n","28/28 [==============================] - 1s 28ms/step - loss: 0.4851 - accuracy: 0.8681\n","Epoch 114/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4978 - accuracy: 0.8688\n","Epoch 115/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4942 - accuracy: 0.8638\n","Epoch 116/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4962 - accuracy: 0.8667\n","Epoch 117/200\n","28/28 [==============================] - 1s 29ms/step - loss: 0.5670 - accuracy: 0.8502\n","Epoch 118/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.5507 - accuracy: 0.8573\n","Epoch 119/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4969 - accuracy: 0.8645\n","Epoch 120/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4774 - accuracy: 0.8695\n","Epoch 121/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4815 - accuracy: 0.8760\n","Epoch 122/200\n","28/28 [==============================] - 1s 44ms/step - loss: 0.4908 - accuracy: 0.8674\n","Epoch 123/200\n","28/28 [==============================] - 1s 41ms/step - loss: 0.4728 - accuracy: 0.8731\n","Epoch 124/200\n","28/28 [==============================] - 1s 34ms/step - loss: 0.4588 - accuracy: 0.8760\n","Epoch 125/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4885 - accuracy: 0.8724\n","Epoch 126/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4750 - accuracy: 0.8724\n","Epoch 127/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4600 - accuracy: 0.8796\n","Epoch 128/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4527 - accuracy: 0.8789\n","Epoch 129/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4557 - accuracy: 0.8767\n","Epoch 130/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4429 - accuracy: 0.8832\n","Epoch 131/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4733 - accuracy: 0.8710\n","Epoch 132/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4766 - accuracy: 0.8753\n","Epoch 133/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4622 - accuracy: 0.8760\n","Epoch 134/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4567 - accuracy: 0.8774\n","Epoch 135/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4327 - accuracy: 0.8839\n","Epoch 136/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4258 - accuracy: 0.8867\n","Epoch 137/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4248 - accuracy: 0.8867\n","Epoch 138/200\n","28/28 [==============================] - 1s 43ms/step - loss: 0.4409 - accuracy: 0.8810\n","Epoch 139/200\n","28/28 [==============================] - 1s 42ms/step - loss: 0.4396 - accuracy: 0.8903\n","Epoch 140/200\n","28/28 [==============================] - 1s 34ms/step - loss: 0.4290 - accuracy: 0.8882\n","Epoch 141/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4277 - accuracy: 0.8839\n","Epoch 142/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4471 - accuracy: 0.8839\n","Epoch 143/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4449 - accuracy: 0.8824\n","Epoch 144/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4309 - accuracy: 0.8882\n","Epoch 145/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4211 - accuracy: 0.8932\n","Epoch 146/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4143 - accuracy: 0.8853\n","Epoch 147/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4011 - accuracy: 0.8946\n","Epoch 148/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3949 - accuracy: 0.8982\n","Epoch 149/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3936 - accuracy: 0.8961\n","Epoch 150/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4392 - accuracy: 0.8839\n","Epoch 151/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.4347 - accuracy: 0.8860\n","Epoch 152/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.4157 - accuracy: 0.8925\n","Epoch 153/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3844 - accuracy: 0.8968\n","Epoch 154/200\n","28/28 [==============================] - 1s 41ms/step - loss: 0.3920 - accuracy: 0.8968\n","Epoch 155/200\n","28/28 [==============================] - 1s 43ms/step - loss: 0.4074 - accuracy: 0.8910\n","Epoch 156/200\n","28/28 [==============================] - 1s 33ms/step - loss: 0.3870 - accuracy: 0.8953\n","Epoch 157/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3941 - accuracy: 0.8925\n","Epoch 158/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3978 - accuracy: 0.8975\n","Epoch 159/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3815 - accuracy: 0.9018\n","Epoch 160/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3755 - accuracy: 0.9054\n","Epoch 161/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3799 - accuracy: 0.9018\n","Epoch 162/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.4038 - accuracy: 0.8910\n","Epoch 163/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3898 - accuracy: 0.8968\n","Epoch 164/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3768 - accuracy: 0.8975\n","Epoch 165/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3734 - accuracy: 0.9039\n","Epoch 166/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3545 - accuracy: 0.9068\n","Epoch 167/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3557 - accuracy: 0.9082\n","Epoch 168/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3539 - accuracy: 0.9082\n","Epoch 169/200\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3543 - accuracy: 0.9111\n","Epoch 170/200\n","28/28 [==============================] - 2s 60ms/step - loss: 0.4017 - accuracy: 0.8910\n","Epoch 171/200\n","28/28 [==============================] - 1s 42ms/step - loss: 0.3554 - accuracy: 0.9097\n","Epoch 172/200\n","28/28 [==============================] - 1s 25ms/step - loss: 0.3592 - accuracy: 0.9097\n","Epoch 173/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3548 - accuracy: 0.9061\n","Epoch 174/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3483 - accuracy: 0.9133\n","Epoch 175/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3592 - accuracy: 0.9011\n","Epoch 176/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3448 - accuracy: 0.9090\n","Epoch 177/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3390 - accuracy: 0.9097\n","Epoch 178/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3753 - accuracy: 0.9054\n","Epoch 179/200\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3487 - accuracy: 0.9111\n","Epoch 180/200\n","28/28 [==============================] - 1s 35ms/step - loss: 0.3321 - accuracy: 0.9161\n","Epoch 181/200\n","28/28 [==============================] - 1s 35ms/step - loss: 0.3347 - accuracy: 0.9190\n","Epoch 182/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3278 - accuracy: 0.9168\n","Epoch 183/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3198 - accuracy: 0.9154\n","Epoch 184/200\n","28/28 [==============================] - 1s 31ms/step - loss: 0.3131 - accuracy: 0.9262\n","Epoch 185/200\n","28/28 [==============================] - 1s 42ms/step - loss: 0.3179 - accuracy: 0.9254\n","Epoch 186/200\n","28/28 [==============================] - 1s 47ms/step - loss: 0.3114 - accuracy: 0.9233\n","Epoch 187/200\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3154 - accuracy: 0.9276\n","Epoch 188/200\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3240 - accuracy: 0.9168\n","Epoch 189/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3149 - accuracy: 0.9254\n","Epoch 190/200\n","28/28 [==============================] - 1s 29ms/step - loss: 0.3474 - accuracy: 0.9061\n","Epoch 191/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3199 - accuracy: 0.9197\n","Epoch 192/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3462 - accuracy: 0.9061\n","Epoch 193/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3372 - accuracy: 0.9176\n","Epoch 194/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3157 - accuracy: 0.9190\n","Epoch 195/200\n","28/28 [==============================] - 1s 28ms/step - loss: 0.3369 - accuracy: 0.9090\n","Epoch 196/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3731 - accuracy: 0.8989\n","Epoch 197/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.3301 - accuracy: 0.9104\n","Epoch 198/200\n","28/28 [==============================] - 1s 26ms/step - loss: 0.3092 - accuracy: 0.9254\n","Epoch 199/200\n","28/28 [==============================] - 1s 27ms/step - loss: 0.2949 - accuracy: 0.9297\n","Epoch 200/200\n","28/28 [==============================] - 1s 41ms/step - loss: 0.2937 - accuracy: 0.9305\n","19/19 [==============================] - 1s 10ms/step\n","0.8430717863105175\n"]}],"source":["model = KerasClassifier(build_fn = lstm, epochs = 200, batch_size = 50, verbose = 1)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","y_test_ = np.argmax(y_test, axis = 1)\n","print(accuracy_score(y_pred, y_test_))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ez9UqYSKjIGN","outputId":"69925624-f390-465a-8a5d-ca1ae40f7d92"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 3  4 24  3  3  3  4 19  3  3  3  3  3 19  3  3  3  4  3  6  3  3  3  3\n","  3  4  4 19  3  3  3  3  3  3  3  3  3  3  3  3  3 19  4  3  3  4  3  3\n","  3  3  3 21  3  3  3  3  3  3  3  3  4  4  3  3  3  3  3  3  3  3  1 20\n","  3  3  3 20  4  9  4  3  4  3  3  4 19  1  3  4  3  3  3  3  3  3  3  3\n","  3  3  3  3 24  3  3 19 14  3  3 19  3  3  3  3  3  3  3  3  3  3  3  3\n","  3  3  3  3 24  4  3  4  3  3  3  3  4  3  4  3  4  3  3  3 24  3  3  3\n","  3 24  4 24  1  3 24  3 19  4  3 17  3  4  3  4  3  3 24  4  4  3  3  3\n","  3  3  3  3  3  4  3  3  3  3  3  3  3  3  3  3  4  3  3  4  3  4  3  3\n","  3  3  3  4  3  3  3  3  3  3  3  4  3 19  3  4  4  3  3  3  3  3  4  3\n","  3  3  3  3  3  4 24  3  3  3  3  4  3  3  3  3  3  3  3  3  3  3  3  4\n","  3  3  3  3  3  1  3  3  3  3  4  3  3  3  3  6  3  3  3  3  3  3  3  4\n","  4  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  4  3\n","  4  3  3 19  3 24  4  3  3  4  3  3  3  3  3  3  4  3 10  3  3 20  4  3\n","  3 14  3  3  3  3  3  4  3  3  3  4  4  4  3  3  3  3  3 19  3  4  3  3\n","  3  3  3  3  3  4  3  4 19  4  3  3  3  3  3  4  3  3  3  4  3  3  3  3\n","  3  3  3  3  3  3 45  4 24  3  3  3 19  3  4  3  3  4  3  3  3  4  3  3\n","  3  4  3 19  3  3 21  3  3  4  4 19  3 10  3  4  4  4  3  3  3  3  3  3\n","  3  3  4  3  3 24  4 19  2  3  3  3  4  3  3 19  3  3  3 19  3  3  3  3\n","  3  4  3  3  3  3  3  3  4  4  3 19  3 24  4  3  3  3  3  4  3  3  3  3\n","  3  3  3  3  3  4  3  3  3  3  4  3  1  3  3  3  3  3  3  4  4  3  3  4\n","  4  3  3  3  4  3  3  3  3  3  2  4  3  1  1  4  3 39  3  3  3  3  3  3\n","  3  1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 20  3  3  3 19  4  3\n","  3  3  3  3  4  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  4  4\n","  3  3  3  3  3  3  4  3  3  3  3  3  3  3  3  3  3  3  4  4  3  3  3  3\n","  4  3  3  3  3  3  3  3  3  4  4  3 24  3  3  4  3  3  3  4  3  3  3]\n"]}],"source":["print(y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCAtJPnsj4vB"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wvx7IufvkRvo"},"source":["https://www.kaggle.com/code/manan5598/simple-vanilla-rnn-and-lstm-implementation/notebook"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}